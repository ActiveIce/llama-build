name: auto build engine

on: 
  release:
    types: [published]
  schedule:
    - cron: "0 16 * * *"
  push:
    branches: 
      - master
  watch:
    types: [started]
   
jobs:
  build:
    runs-on: windows-2025

    steps:
    - name: Setup cmake
      uses: jwlawson/actions-setup-cmake@master
    
    - name: Install ccache
      uses: ggml-org/ccache-action@main
      with:
        key: windows-cuda-12.4
        variant: ccache
        evict-old-files: 1d
    
    - name: libCURL
      id: get_libcurl
      shell: powershell
      env:
        CURL_VERSION: '8.6.0_6'
        ARCHITECTURE: 'win64'
      run: |
        curl.exe -o $env:RUNNER_TEMP/curl.zip -L "https://curl.se/windows/dl-${env:CURL_VERSION}/curl-${env:CURL_VERSION}-${env:ARCHITECTURE}-mingw.zip"
        mkdir $env:RUNNER_TEMP/libcurl
        tar.exe -xvf $env:RUNNER_TEMP/curl.zip --strip-components=1 -C $env:RUNNER_TEMP/libcurl
        echo "curl_path=$env:RUNNER_TEMP/libcurl" >> $env:GITHUB_OUTPUT
    
    - name: Install Cuda Toolkit
      shell: pwsh
      run: |
          mkdir -p "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0"
          choco install unzip -y
          curl -O "https://developer.download.nvidia.com/compute/cuda/redist/cuda_cccl/windows-x86_64/cuda_cccl-windows-x86_64-13.0.85-archive.zip"
          curl -O "https://developer.download.nvidia.com/compute/cuda/redist/cuda_crt/windows-x86_64/cuda_crt-windows-x86_64-13.0.88-archive.zip"
          curl -O "https://developer.download.nvidia.com/compute/cuda/redist/cuda_cudart/windows-x86_64/cuda_cudart-windows-x86_64-13.0.88-archive.zip"
          curl -O "https://developer.download.nvidia.com/compute/cuda/redist/cuda_nvcc/windows-x86_64/cuda_nvcc-windows-x86_64-13.0.88-archive.zip"
          curl -O "https://developer.download.nvidia.com/compute/cuda/redist/libcublas/windows-x86_64/libcublas-windows-x86_64-13.0.2.14-archive.zip"
          curl -O "https://developer.download.nvidia.com/compute/cuda/redist/libnvvm/windows-x86_64/libnvvm-windows-x86_64-13.0.88-archive.zip"
          unzip '*.zip' -d "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0"
          xcopy "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\cuda_cccl-windows-x86_64-13.0.85-archive\*" "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0" /E /I /H /Y
          xcopy "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\cuda_crt-windows-x86_64-13.0.88-archive\*" "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0" /E /I /H /Y
          xcopy "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\cuda_cudart-windows-x86_64-13.0.88-archive\*" "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0" /E /I /H /Y
          xcopy "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\cuda_nvcc-windows-x86_64-13.0.88-archive\*" "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0" /E /I /H /Y
          xcopy "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\libcublas-windows-x86_64-13.0.2.14-archive\*" "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0" /E /I /H /Y
          xcopy "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0\libnvvm-windows-x86_64-13.0.88-archive\*" "C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0" /E /I /H /Y
          echo "CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v13.0" | Out-File -FilePath $env:GITHUB_ENV -Append -Encoding utf8
    
    - name: Install Ninja
      run: |
        choco install ninja
    
    - name: Build
      shell: cmd
      env:
          CURL_PATH: ${{ steps.get_libcurl.outputs.curl_path }}
      run: |
        git clone https://github.com/ggml-org/llama.cpp --depth 1
        pushd llama.cpp
        call "C:\Program Files\Microsoft Visual Studio\2022\Enterprise\VC\Auxiliary\Build\vcvarsall.bat" x64
        cmake -S . -B build -G "Ninja Multi-Config" ^
          -DCMAKE_TOOLCHAIN_FILE=cmake/x64-windows-llvm.cmake ^
          -DGGML_BACKEND_DL=ON ^
          -DGGML_NATIVE=OFF ^
          -DGGML_CPU=OFF ^
          -DGGML_CUDA=ON ^
          -DGGML_CUDA_FORCE_CUBLAS=ON ^
          -DCMAKE_CUDA_ARCHITECTURES="75-virtual;80-virtual;86-virtual;89-real;90-virtual;100-virtual;120-real" ^
          -DCURL_LIBRARY="%CURL_PATH%/lib/libcurl.dll.a" -DCURL_INCLUDE_DIR="%CURL_PATH%/include" ^
          -DLLAMA_BUILD_EXAMPLES=OFF -DLLAMA_BUILD_TESTS=OFF -DLLAMA_BUILD_TOOLS=ON -DLLAMA_BUILD_SERVER=ON -DGGML_RPC=ON
        set /A NINJA_JOBS=%NUMBER_OF_PROCESSORS%-1
        cmake --build build --config Release -j %NINJA_JOBS%
        popd

    - name: Pack artifacts
      run: |
        robocopy "${{env.CUDA_PATH}}\bin\x64" ".\llama.cpp\build\bin\Release\" cudart64_*.dll cublas64_*.dll cublasLt64_*.dll
        ls .\llama.cpp\build\bin\Release\
        #7z a llama-bin-win-cuda-${{ matrix.cuda }}-x64.zip .\llama.cpp\build\bin\Release\ggml-cuda.dll
